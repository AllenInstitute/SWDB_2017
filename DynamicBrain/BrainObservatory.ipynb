{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>This notebook will introduce you to the Allen Brain Observatory dataset and SDK functions. \n",
    "\n",
    "<p>We want to look at signal correlations between all the neurons in a given experiment and see whether this is related to the distance between the cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure your drive path is correct!\n",
    "drive_path = '/local1/Documents/projects/cam_analysis/boc/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to import these modules to get started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The main entry point is the `BrainObservatoryCache` class.  This class is responsible for downloading any requested data or metadata as needed and storing it in well known locations.  For this workshop, all of the data has been preloaded onto the hard drives you have received.\n",
    "\n",
    "<p>We begin by importing the `BrainObservatoryCache` class and instantiating it.\n",
    "\n",
    "<p>`manifest_path` is a path to the manifest file.  We will use the manifest file preloaded onto your Workshop hard drives.  Make sure that `drive_path` is set correctly for your platform.  (See the first cell in this notebook.)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "# manifest_file = os.path.join(drive_path,'manifest.json')\n",
    "manifest_file=\"/data/dynamic-brain-workshop/brain_observatory_cache/brain_observatory_manifest.json\"\n",
    "\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.1:**  Get information about what's in the dataset from BrainObservatoryCache\n",
    "\n",
    "<p>The following methods for BrainObservatoryCache retrieve the available depths, cre lines, areas, and stimuli.  Notice that these parameters outline the 'data cube'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all targeted structures: [u'VISal', u'VISam', u'VISl', u'VISp', u'VISpm', u'VISrl']\n",
      "all imaging depths: [175, 265, 275, 300, 320, 325, 335, 350, 365, 375, 435]\n",
      "all cre lines: [u'Cux2-CreERT2', u'Emx1-IRES-Cre', u'Nr5a1-Cre', u'Rbp4-Cre_KL100', u'Rorb-IRES2-Cre', u'Scnn1a-Tg3-Cre']\n",
      "all stimuli: ['drifting_gratings', 'locally_sparse_noise', 'locally_sparse_noise_4deg', 'locally_sparse_noise_8deg', 'natural_movie_one', 'natural_movie_three', 'natural_movie_two', 'natural_scenes', 'spontaneous', 'static_gratings']\n"
     ]
    }
   ],
   "source": [
    "# Download a list of all targeted areas\n",
    "targeted_structures = boc.get_all_targeted_structures()\n",
    "print 'all targeted structures: ' + str(targeted_structures)\n",
    "\n",
    "# Download a list of all imaging depths\n",
    "depths = boc.get_all_imaging_depths()\n",
    "print 'all imaging depths: ' + str(depths)\n",
    "\n",
    "# Download a list of all cre driver lines \n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print 'all cre lines: ' + str(cre_lines)\n",
    "\n",
    "# Download a list of all stimuli\n",
    "stims = boc.get_all_stimuli()\n",
    "print 'all stimuli: ' + str(stims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.2:**  Use tab completion in Jupyter to see what other methods the BrainObservatoryCache has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hit the 'tab' key with the cursor just after the '.'\n",
    "boc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Experiment containers</h2>\n",
    "<p>The experiment container describes a set of 3 experiment sessions performed at the same location (targeted area and imaging depth) in the same mouse that targets the same set of cells. Each experiment container has a unique ID number.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.3:**  Choose a visual area and Cre line from the lists above to examine in the rest of the notebook\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visual_area = 'VISp'\n",
    "cre_line ='Cux2-CreERT2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.4:**  Get the list of all the experiment containers for that area and Cre line combination.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exps = boc.get_experiment_containers(targeted_structures=[visual_area], cre_lines=[cre_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cre_line</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>failed</th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>targeted_structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>248894</td>\n",
       "      <td>False</td>\n",
       "      <td>528792730</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-248894</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>248895</td>\n",
       "      <td>False</td>\n",
       "      <td>528799602</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-248895</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250606</td>\n",
       "      <td>False</td>\n",
       "      <td>531100608</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250606</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>257786</td>\n",
       "      <td>False</td>\n",
       "      <td>538803515</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-257786</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250605</td>\n",
       "      <td>False</td>\n",
       "      <td>529763300</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250605</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>255445</td>\n",
       "      <td>False</td>\n",
       "      <td>532233174</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-255445</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250606</td>\n",
       "      <td>False</td>\n",
       "      <td>539291370</td>\n",
       "      <td>335</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250606</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>279430</td>\n",
       "      <td>False</td>\n",
       "      <td>569811199</td>\n",
       "      <td>300</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-279430</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>286360</td>\n",
       "      <td>False</td>\n",
       "      <td>570278595</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-286360</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cre_line donor_name failed         id  imaging_depth       reporter_line  \\\n",
       "0  Nr5a1-Cre     248894  False  528792730            350  Ai93(TITL-GCaMP6f)   \n",
       "1  Nr5a1-Cre     248895  False  528799602            350  Ai93(TITL-GCaMP6f)   \n",
       "2  Nr5a1-Cre     250606  False  531100608            350  Ai93(TITL-GCaMP6f)   \n",
       "3  Nr5a1-Cre     257786  False  538803515            350  Ai93(TITL-GCaMP6f)   \n",
       "4  Nr5a1-Cre     250605  False  529763300            350  Ai93(TITL-GCaMP6f)   \n",
       "5  Nr5a1-Cre     255445  False  532233174            350  Ai93(TITL-GCaMP6f)   \n",
       "6  Nr5a1-Cre     250606  False  539291370            335  Ai93(TITL-GCaMP6f)   \n",
       "7  Nr5a1-Cre     279430  False  569811199            300  Ai93(TITL-GCaMP6f)   \n",
       "8  Nr5a1-Cre     286360  False  570278595            350  Ai93(TITL-GCaMP6f)   \n",
       "\n",
       "                      specimen_name tags targeted_structure  \n",
       "0  Nr5a1-Cre;Camk2a-tTA;Ai93-248894   []               VISp  \n",
       "1  Nr5a1-Cre;Camk2a-tTA;Ai93-248895   []               VISp  \n",
       "2  Nr5a1-Cre;Camk2a-tTA;Ai93-250606   []               VISp  \n",
       "3  Nr5a1-Cre;Camk2a-tTA;Ai93-257786   []               VISp  \n",
       "4  Nr5a1-Cre;Camk2a-tTA;Ai93-250605   []               VISp  \n",
       "5  Nr5a1-Cre;Camk2a-tTA;Ai93-255445   []               VISp  \n",
       "6  Nr5a1-Cre;Camk2a-tTA;Ai93-250606   []               VISp  \n",
       "7  Nr5a1-Cre;Camk2a-tTA;Ai93-279430   []               VISp  \n",
       "8  Nr5a1-Cre;Camk2a-tTA;Ai93-286360   []               VISp  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make a pandas DataFrame to see what information we have on these experiments\n",
    "pd.DataFrame(exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.5:**  Pick a random experiment from this selection\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539291370\n"
     ]
    }
   ],
   "source": [
    "expt_container_id = np.random.choice(exps)['id']\n",
    "print expt_container_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.6:** Get information about all of the experiment <strong>sessions</strong> in your experiment <strong>container</strong>.  This is accomplished with the `get_ophys_experiments` method.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'imaging_depth': 335, 'experiment_container_id': 539291370, 'reporter_line': u'Ai93(TITL-GCaMP6f)', 'targeted_structure': u'VISp', 'cre_line': u'Nr5a1-Cre', 'session_type': u'three_session_B', 'donor_name': u'250606', 'id': 539291372, 'acquisition_age_days': 119, 'specimen_name': u'Nr5a1-Cre;Camk2a-tTA;Ai93-250606'}, {'imaging_depth': 335, 'experiment_container_id': 539291370, 'reporter_line': u'Ai93(TITL-GCaMP6f)', 'targeted_structure': u'VISp', 'cre_line': u'Nr5a1-Cre', 'session_type': u'three_session_C', 'donor_name': u'250606', 'id': 539540432, 'acquisition_age_days': 120, 'specimen_name': u'Nr5a1-Cre;Camk2a-tTA;Ai93-250606'}, {'imaging_depth': 335, 'experiment_container_id': 539291370, 'reporter_line': u'Ai93(TITL-GCaMP6f)', 'targeted_structure': u'VISp', 'cre_line': u'Nr5a1-Cre', 'session_type': u'three_session_A', 'donor_name': u'250606', 'id': 539487468, 'acquisition_age_days': 120, 'specimen_name': u'Nr5a1-Cre;Camk2a-tTA;Ai93-250606'}]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "expt_session_info = boc.get_ophys_experiments(experiment_container_ids=[expt_container_id])\n",
    "print(expt_session_info)\n",
    "print len(expt_session_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>`get_experiment_containers` returns a list of dictionaries that contain information about <b>experiment containers</b>.\n",
    "\n",
    "<p>`get_ophys_experiments` returns a list of dictionaries that contain information about <b>experiment sessions</b>.  Here we are using keyword arguments to return just those experiment sessions that belong to our experiment container. We could have used targeted structures and Cre lines to find all the experiment sessions in our chosen location.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.7:** Create a dataframe of the experiment sessions in your chosen container.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_age_days</th>\n",
       "      <th>cre_line</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>experiment_container_id</th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>session_type</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>targeted_structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250606</td>\n",
       "      <td>539291370</td>\n",
       "      <td>539291372</td>\n",
       "      <td>335</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>three_session_B</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250606</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250606</td>\n",
       "      <td>539291370</td>\n",
       "      <td>539540432</td>\n",
       "      <td>335</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>three_session_C</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250606</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>250606</td>\n",
       "      <td>539291370</td>\n",
       "      <td>539487468</td>\n",
       "      <td>335</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-250606</td>\n",
       "      <td>VISp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acquisition_age_days   cre_line donor_name  experiment_container_id  \\\n",
       "0                   119  Nr5a1-Cre     250606                539291370   \n",
       "1                   120  Nr5a1-Cre     250606                539291370   \n",
       "2                   120  Nr5a1-Cre     250606                539291370   \n",
       "\n",
       "          id  imaging_depth       reporter_line     session_type  \\\n",
       "0  539291372            335  Ai93(TITL-GCaMP6f)  three_session_B   \n",
       "1  539540432            335  Ai93(TITL-GCaMP6f)  three_session_C   \n",
       "2  539487468            335  Ai93(TITL-GCaMP6f)  three_session_A   \n",
       "\n",
       "                      specimen_name targeted_structure  \n",
       "0  Nr5a1-Cre;Camk2a-tTA;Ai93-250606               VISp  \n",
       "1  Nr5a1-Cre;Camk2a-tTA;Ai93-250606               VISp  \n",
       "2  Nr5a1-Cre;Camk2a-tTA;Ai93-250606               VISp  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expt_session_info_df = pd.DataFrame(expt_session_info)\n",
    "expt_session_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sessions are in your experiment container? What is different about each session? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 1.3:**  Find the session id for the session that has Natural Scenes as a stimulus for your chosen experiment container.  Save this as `session_id`. (Hint: you can either know which session type contains the Natural Scenes stimulus, or you can use the stimulus to select the experiment session)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>We will be using the session you have recorded in `session_id` for much of the remainder of this notebook.\n",
    "\n",
    "<h2>The Dataset Object</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.1:**  Create a data_set object for this experiment session.\n",
    "\n",
    "The data_set object contains methods and info for a single experiment session (one of the 3 in the experiment container)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a data_set object\n",
    "data_set = boc.get_ophys_experiment_data(ophys_experiment_id=session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.2:** Use either `dir` or tab-completion to find out what methods the new `data_set` object has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>Using the methods you find, perform the following exercises.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.1:** Get the metadata for your data set. How old was the mouse in this experiment?  Was it male or female?  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.3:** Get the max projection image for your data set. Display it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.5:** Get the roi mask for all the cells.  (Hint:  There are two methods that return roi masks.  In one of them masks are returned as lists of python objects.  What methods do they have?  What is the type of this object?)  What is the size and shape of the mask? How many cells are in this experiment session?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.6:** Pick one cell (at random) and plot the mask overlayed on the max projection.  (Hint:  imshow has an optional parameter called `alpha`.) What is the structure of the mask - how can you find the position of the mask?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.7:** Calculate the centroid of the ROI mask. Verify that you've calculated this properly by plotting it on top of the mask\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.7:** Find the centroid of each roi mask and calculate the distance between all the ROIs\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 2.8:** Plot the distribution of distances. Only count each distance once! (Hint: numpy has functions to select the upper or lower triangle of an array. Look for triu, or triu_indices. Be sure to eliminate the diagonal itself)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Analysis Object</h2>\n",
    "\n",
    "\n",
    "<p>The analysis objects summarize the trial data for a stimulus type and provide convenient DataFrame objects.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.1:**  Import the `NaturalScenes` object and instatiate it with `data_set`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "NS = NaturalScenes(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.1:** Get the \"signal correlations\" of the responses to natural scenes. You can opt for pearson or spearman - pearson is faster but spearman is better. (Either this way will take a bit of time to run  - this is a great time for a bathroom break) What is the shape of this object?  The methods will return a tuple of length two.  The first value is the signal correlation, the second the p values for .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.2:** Plot the signal correlation vs distance for all pairs of cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.3:** Find the most signal-correlated pair of neurons in this experiment and plot their ROIs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to look at the trial-by-trials responses of these cells to their preferred stimuli. To do this we're going to pull out the responses from our analysis object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>sweep_response is a DataFrame that contains the dF/F response of each cell during each stimulus trial. It shares its index with stim_table. Each cell contains a timeseries that extends from 1 second prior to the start of the trial to 1 second after the end of the trial. The sweep_response table is organized as cells (columns) for each sweep (rows)\n",
    "\n",
    "<p>mean_sweep_response provides the time-averaged dF/F for each trial.\n",
    "\n",
    "<p>The stimulus_table object contains information about the stimulus. Use data_set.get_stimulus_table('natural_scenes') to get this object. What does it contain?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.4:** Get the mean sweep responses of your two cells to natural images. What shape are these?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.5:** Get the natural scenes stimulus table. What shape is it? What are its columns?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.6:** Use the stimulus table to get the mean sweep responses to natural image 10. Plot your two cells' mean sweep responses to it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.7:** Get the trial-averaged mean sweep responses to each natural scene for your two cells. (Hint: in addition to using mean_sweep_response and the stimulus table, try checking NS.response.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.8:** Plot the neurons' preferred images. (Hint: get the stimulus_template object from the data_set. What shape is it?) (Hint2: pay attention to the image indices and the frame labels in the stimulus table)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 3.9:** Plot the two neurons' trial-by-trial sweep responses to their preferred images. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Mouse Behavior</h2>\n",
    "\n",
    "\n",
    "<p>The data_set and analysis objects also contain information about the mouse's running speed and eye tracking. (Not all experiments have eye tracking information.) The running speed, eye position and pupil size can be extracted from the data_set object using appropriately named functions. The running speed has been analyzed the same way as each fluorescent trace, and contained in the final column of the sweep_response and mean_sweep_response dataframes named \"dx\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 4.1:** Plot the mouse's running speed over the whole experiment and on the same trials you looked at responses of above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 4.2:** Check if your experiment has information about the mouse's pupil diameter. If so, plot it on the sweeps of each neuron's preferred image.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Cell Specimens Object</h2>\n",
    "\n",
    "\n",
    "<p>The cell specimens object contains summary information about all cells in the brain observatory dataset. Let's find your two cells in it and compare them! First, load the cell_specimens object and see what types of information it contains about each cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_specimens = boc.get_cell_specimens()\n",
    "print cell_specimens.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 5.1:** Find your two cells' cell specimen ids in the data_set object.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Exercise 5.2:** Get the cell_specimens information for just your two cells. (Hint: when you create the cell_specimens object, you can filter by cell specimen id.) What is each of their response reliability for natural scenes? How does it compare to their reliability for static gratings?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
